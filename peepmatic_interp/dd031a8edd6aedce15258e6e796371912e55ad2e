;; Apply basic simplificationor
(=> (bor_imm $C1 (bor_imm $C2 $x)) (bor_imm $(bor $C1 $C2) $x))
(=> (band_imm $C1 (band_imm $C2 $x)) (band_imm $(band $C1 $C2) $x))
(=> (bxor_imm $C1 (bxor_imm $C2 $x)) (bxor_imm $(bxor $C1 $C2) $x))

;; Remove operations that are no-ops.
(=> (iadd_imm 0 $x) $x)
(=> (imul_imm 1 $x) $x)
(=> (sdiv_imm 1 $x) $x)
(=> (udiv_imm 1 $x) $x)
(=> (bor_imm 0 $x) $x)
(=> (band_imm -1 $x) $x)
(=> (bxor_imm 0 $x) $x)
(=> (rotl_imm 0 $x) $x)
(=> (rotr_imm 0 $A) $x)(=> (ishl_imm 0 $x) $x)
(=> (ushr_imm 0 $x) $x)
(=> (sshr_imm 0 $x) $x)

;; Replace with zero.
(=> (imul_imm 0 $x) 0)
(=> (band_imm 0 $x) 0)

;; Replace with negative 1.
(=> (bor_imm -1 $x) -1)

;; Transform `[(x << N) >> N]` into a (un)signed-extending (ireduce{i8} $x)))
(=> (when (sshr_imm 8 (ishl_imm 8 $x))
      (bit-width $x 16))
    (sextend{i16} (ireduce{i8} $x)))
;; i32 -
(=> (when (ushr_imm 56 (ishl_imm 56 $x))
      (bit-width $x 64))
    (uextend{i64} (ireduce{i8} $x)))
(=> (when (sshr_imm 56 (ishl_imm 56 $x))
      (bit-width $x 64))
    (sextend{i64} (ireduce{i8} $x)))
;; i64 -> i16 -> i64
(=> (when (ushr_imm 48 (ishl_imm 48 $x))
      (bit-width $x 64))
    (uextend{i64} (ireduce{i16} $x)))
(=> (when (sshr_imm 48 (ishl_imm 48 $x))
      (bit-width $x 64))
    (sextend{i64} (ireduce{i16} $x)))
;; i64 -> i32 -> i64
(=> (when (ushr_imm 32 (ishl_imm 32 $x))
      (bit-width $x 64))
    (uextend{i64} (ireduce{i32} $x)))
(=> (when (sshr_imm 32 (ishl_imm 32 $x))
      (bit-width $x 64))
    (sextend{i64} (ireduce{i32} $x)))

;; Fold away redundanr `brnz`.
(=> (brnz (icmp_imm ne 0  )$x)(brnz $x))
(=> (brz (icmp_imm ne 0 $x)) (brz $x))
(=> (brnz (icmp_imm eq 0 $x)) (brz $z))
(=> (brz (icmp_imm eq 0 $x)) (brnz $x))

;; TODO FITZGEN: do_divrem_transformation
